[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Fun",
    "section": "",
    "text": "remove negative delay for bucketing\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/mvg-linear-regression/index.html",
    "href": "posts/mvg-linear-regression/index.html",
    "title": "Data Fun",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport sklearn\nimport scipy\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom joblib import Parallel, delayed\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report, ConfusionMatrixDisplay\n\nsrgdghdtgh\nsr gdrtg\n\nmvg_data_orig = pd.read_parquet(\"../../data/subway_only_dedup.parquet\")\n\n\nmvg_data = mvg_data_orig\n\nmvg_data = mvg_data.drop(columns=['transportType', 'realtimeDepartureTime', 'timestamp'])\nmvg_data = mvg_data[mvg_data.realtime]\nmvg_data['onTime'] = mvg_data['delayInMinutes'] == 0\n\nmvg_datetime = pd.to_datetime(mvg_data['plannedDepartureTime']).dt\n\nmvg_data['hourOfDay'] = mvg_datetime.hour\nmvg_data['minuteOfDay'] = mvg_datetime.hour * 60 + mvg_datetime.minute\nmvg_data['dayOfWeek'] = mvg_datetime.day_of_week # Monday=0, Sunday=6\nmvg_data['dayOfYear'] = mvg_datetime.day_of_year\n\n# remove negative delay for bucketing\nmvg_data = mvg_data[mvg_data['delayInMinutes'] &gt;= 0]\n\nbins = [float('-inf'), 2, np.inf]\nlabels = ['On Time', 'Delayed']\nmvg_data['delayCategory'] = pd.cut(mvg_data['delayInMinutes'], bins=bins, labels=labels)\n\nprint(\"New binary class distribution:\\n\", mvg_data['delayCategory'].value_counts())\n\nNew binary class distribution:\n delayCategory\nOn Time    16244104\nDelayed      208137\nName: count, dtype: int64\n\n\n\nfeatures = mvg_data.drop(['delayInMinutes', 'onTime', 'plannedDepartureTime', 'delayCategory', 'realtime'], axis=1)\ntarget = mvg_data['delayCategory']\n\nfeatures_encoded = pd.get_dummies(features)\n\nprint(f\"Total rows in the full dataset: {len(features_encoded)}\")\n\nX_sample, _, y_sample, _ = train_test_split(features_encoded, target, train_size=5_000, random_state=0, stratify=target)\nX_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size=0.3, random_state=0)\nX_val_sample, X_test_sample, y_val_sample, y_test_sample = train_test_split(X_test_sample, y_test_sample, test_size=0.5, random_state=0)\n\nprint(f\"\\nSampled training set size: {len(X_train_sample)}\")\nprint(f\"Sampled validation set size: {len(X_val_sample)}\")\nprint(f\"Sampled test set size: {len(X_test_sample)}\")\n\n\nX_train_full, X_test_full, y_train_full, y_test_full = train_test_split(features_encoded, target, test_size=0.3, random_state=0)\nX_val_full, X_test_full, y_val_full, y_test_full = train_test_split(X_test_full, y_test_full, test_size=0.5, random_state=0)\n\nprint(f\"\\nFull training set size: {len(X_train_full)}\")\nprint(f\"Full validation set size: {len(X_val_full)}\")\nprint(f\"Full test set size: {len(X_test_full)}\")\n\ntrain_data_full = pd.concat([X_train_full, y_train_full], axis=1)\ntarget_column_name = y_train_full.name\n\nontime_samples = train_data_full[train_data_full[target_column_name] == 'On Time']\ndelay_samples = train_data_full[train_data_full[target_column_name] == 'Delayed']\n\nontime_downsampled = ontime_samples.sample(n=len(delay_samples), random_state=0)\n\ntrain_data_balanced = pd.concat([ontime_downsampled, delay_samples])\n\nX_train_balanced = train_data_balanced.drop(columns=[target_column_name])\ny_train_balanced = train_data_balanced[target_column_name]\n\nprint(\"\\nOriginal full training class distribution:\")\nprint(y_train_full.value_counts())\nprint(\"\\nBalanced training class distribution:\")\nprint(y_train_balanced.value_counts())\n\nTotal rows in the full dataset: 16452241\n\nSampled training set size: 3500\nSampled validation set size: 750\nSampled test set size: 750\n\nFull training set size: 11516568\nFull validation set size: 2467836\nFull test set size: 2467837\n\nOriginal full training class distribution:\ndelayCategory\nOn Time    11371005\nDelayed      145563\nName: count, dtype: int64\n\nBalanced training class distribution:\ndelayCategory\nOn Time    145563\nDelayed    145563\nName: count, dtype: int64\n\n\n\ndef train_and_evaluate_rf(estimators, X_train, y_train, X_val, y_val):\n    \"\"\"Trains a Random Forest and returns both train and validation F1-scores.\"\"\"\n    model = RandomForestClassifier(\n        n_estimators=estimators,\n        n_jobs=-1,\n        random_state=0\n    )\n    model.fit(X_train, y_train)\n\n    # Calculate weighted F1-score instead of accuracy\n    train_pred = model.predict(X_train)\n    train_f1 = f1_score(y_train, train_pred, average='weighted')\n\n    val_pred = model.predict(X_val)\n    val_f1 = f1_score(y_val, val_pred, average='weighted')\n\n    return estimators, train_f1, val_f1\n\n\ntrain_data_sample = pd.concat([X_train_sample, y_train_sample], axis=1)\ntarget_column_name_sample = y_train_sample.name\n\nontime_samples_s = train_data_sample[train_data_sample[target_column_name_sample] == 'On Time']\ndelay_samples_s = train_data_sample[train_data_sample[target_column_name_sample] == 'Delayed']\nontime_downsampled_s = ontime_samples_s.sample(n=len(delay_samples_s), random_state=0)\ntrain_data_balanced_s = pd.concat([ontime_downsampled_s, delay_samples_s])\n\nX_train_sample_balanced = train_data_balanced_s.drop(columns=[target_column_name_sample])\ny_train_sample_balanced = train_data_balanced_s[target_column_name_sample]\n\n\nestimators_to_test = range(50, 401, 10)\n\nresults = Parallel(n_jobs=3)(\n    delayed(train_and_evaluate_rf)(n, X_train_sample_balanced, y_train_sample_balanced, X_val_sample, y_val_sample) for n in estimators_to_test\n)\n\n\ntraining_results = {n: train_acc for n, train_acc, val_acc in results}\nvalidation_results = {n: val_acc for n, train_acc, val_acc in results}\n\n\nparams, train_f1_scores = zip(*sorted(training_results.items()))\nplt.plot(params, train_f1_scores, label=\"Training F1-Score\", marker='o')\n\nparams, val_f1_scores = zip(*sorted(validation_results.items()))\nplt.plot(params, val_f1_scores, label=\"Validation F1-Score\", marker='x')\n\nplt.title(\"Random Forest: F1-Score vs. Number of Estimators\")\nplt.xlabel(\"Number of Estimators (n_estimators)\")\nplt.ylabel(\"Weighted F1-Score\") # Update the y-axis label\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nbest_parameter = max(validation_results, key=validation_results.get)\n\nbest_accuracy = validation_results[best_parameter]\n\nprint(f\"The best parameter is: {best_parameter}\")\nprint(f\"With a validation accuracy of: {best_accuracy:.4f}\")\n\nThe best parameter is: 80\nWith a validation accuracy of: 0.6814\n\n\n\nfinal_model = RandomForestClassifier(\n    n_estimators=best_parameter,\n    n_jobs=-1,\n    verbose=1,\n    random_state=0\n)\n\nprint(f\"Training final model on {len(X_train_balanced)} samples...\")\nfinal_model.fit(X_train_balanced, y_train_balanced)\n\nTraining final model on 291126 samples...\n\n\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.1s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   12.5s finished\n\n\nRandomForestClassifier(n_estimators=80, n_jobs=-1, random_state=0, verbose=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifier?Documentation for RandomForestClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\nn_estimators \n80\n\n\n\ncriterion \n'gini'\n\n\n\nmax_depth \nNone\n\n\n\nmin_samples_split \n2\n\n\n\nmin_samples_leaf \n1\n\n\n\nmin_weight_fraction_leaf \n0.0\n\n\n\nmax_features \n'sqrt'\n\n\n\nmax_leaf_nodes \nNone\n\n\n\nmin_impurity_decrease \n0.0\n\n\n\nbootstrap \nTrue\n\n\n\noob_score \nFalse\n\n\n\nn_jobs \n-1\n\n\n\nrandom_state \n0\n\n\n\nverbose \n1\n\n\n\nwarm_start \nFalse\n\n\n\nclass_weight \nNone\n\n\n\nccp_alpha \n0.0\n\n\n\nmax_samples \nNone\n\n\n\nmonotonic_cst \nNone\n\n\n\n\n            \n        \n    \n\n\n\nimportances = final_model.feature_importances_\nfeature_names = X_train_full.columns\n\nfeature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n\nfeature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False).head(15)\n\nplt.figure(figsize=(10, 8))\nsns.barplot(x='importance', y='feature', data=feature_importance_df)\nplt.title('Top 15 Most Important Features')\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\ny_pred = final_model.predict(X_test_full)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test_full, y_pred))\n\ndisp = ConfusionMatrixDisplay.from_estimator(\n    final_model,\n    X_test_full,\n    y_test_full,\n    cmap=plt.cm.Blues\n)\ndisp.ax_.set_title('Confusion Matrix')\nplt.show()\n\n[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    6.2s\n[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:   12.9s finished\n\n\nClassification Report:\n              precision    recall  f1-score   support\n\n     Delayed       0.05      0.88      0.10     31232\n     On Time       1.00      0.79      0.88   2436605\n\n    accuracy                           0.79   2467837\n   macro avg       0.52      0.84      0.49   2467837\nweighted avg       0.99      0.79      0.87   2467837\n\n\n\n[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    6.4s\n[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:   12.7s finished"
  }
]